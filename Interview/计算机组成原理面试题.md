## 一个中文占多少字节

一个中文字符占多少字节跟编码密切相关

- UTF-8编码：一个中文字符通常占据 3 个字节

  UTF-8是一种变长编码方式，对于英文字母和数字等 ASCII 字符，每个字符占用 1 个字节；而对于汉字等非 ASCII 字符，每个字符占用 3 个字节

- GBK编码：一个中文字符通常占据 2 个字节

在 JavaScript 中，通常使用 UTF-16 编码，而网页通常是 UTF-8 编码，所以使用 JavaScript 内部的字符串方法时，实际上内部会做一个转换，是以 UTF-16 为准

```bash
"😂".length; // 2
```

码元（code unit），是指存储字符的最小单位，这里即 2 个字节。所以 length 就是码元的个数，上面的表情符号用了 4 个字节，所以是 2 个码元，所以 length 是 2

## 0.1+0.2!=0.3

> JavaScript 中的 Number 类型有 18437736874454810627(即 `2^64-2^53+3`) 个值。9007199254740992(16位数字，即 `2^53-1`)就是 JavaScript 能表示精度最大的整数

在 IEEE 754 标准中，浮点数的表示是有限的，而 0.1 和 0.2 在二进制下是无限循环小数

- 十进制小数转为 2 进制，采用的是 "乘 2 取整，顺序排列" 法，0.1 在由十进制转换为二进制时出现了无限循环，所以无法精准转换，这也就是 `0.1+0.2!=0.3`
- 但是 `0.1+0.1==0.2`，这个为什么呢？

在 IEEE 754 标准中的 64 位浮点数的小数部分，最多有 53 位, 2 的 53 次方就是 16 位数字，所以小数部分最多展示 16 位

- 0.1 + 0.1 正好 16 位（四舍五入）截断，等于 0.2

```bash
(0.1).toPrecision(16); // "0.1000000000000000"
(0.1).toPrecision(17); // "0.10000000000000001"
```

如何避免？

- 使用将数字转化为字符串，然后模拟加法运算，一些库就是这样实现的，所以更建议使用成熟的第三方库
- 当然，这种模拟运算性能并不好，相比于支持 decimal 类型的语言

## CPU与GPU

CPU 是一种通用处理器，适用于各种计算任务。GPU 是一种专用处理器，适用于并行计算任务，例如：图形渲染

GPU 具有大量的计算核心和高速内存，可以同时执行大量的计算任务，因此在处理大规模数据和并行计算任务时，GPU 比 CPU 更快更高效

前端可以利用GPU加速来提高图形渲染和计算性能。

在浏览器中，GPU 加速可以通过 CSS 属性来开启。以下是一些常用的 CSS 属性，可以开启 GPU 加速：

- transform
- opacity
- filter
- will-change
- ...